{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape, Merge\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adadelta\n",
    "from keras.constraints import unitnorm, maxnorm\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# This import to resolve some errors with tf version on office server\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = cPickle.load(open('text-w-map-vocab.pickle', 'rb'))\n",
    "revs, W, word_idx_map, vocab = x[0], x[1], x[2], x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = cPickle.load(open(\"train-test-val.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, val, test = datasets[0], datasets[1], datasets[2]\n",
    "y_helpful_train, y_helpful_val, y_helpful_test =datasets[3], datasets[4], datasets[5]\n",
    "y_helpful_cat_train, y_helpful_cat_val, y_helpful_cat_test = datasets[6], datasets[7], datasets[8]\n",
    "y_staff_train, y_staff_val, y_staff_test = datasets[9], datasets[10], datasets[11]\n",
    "y_staff_cat_train, y_staff_cat_val, y_staff_cat_test = datasets[12], datasets[13], datasets[14]\n",
    "y_knowledge_train, y_knowledge_val, y_knowledge_test = datasets[15], datasets[16], datasets[17]\n",
    "y_knowledge_cat_train, y_knowledge_cat_val, y_knowledge_cat_test = datasets[18], datasets[19], datasets[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab)+1, 300, dropout=0.2, mask_zero=True))\n",
    "model.add(LSTM(300, dropout_W=0.2, dropout_U=0.2))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27151 samples, validate on 6849 samples\n",
      "Epoch 1/7\n",
      "27151/27151 [==============================] - 2609s - loss: 0.4833 - acc: 0.7679 - val_loss: 0.3001 - val_acc: 0.8644\n",
      "Epoch 2/7\n",
      "27151/27151 [==============================] - 3057s - loss: 0.3354 - acc: 0.8523 - val_loss: 0.2440 - val_acc: 0.8918\n",
      "Epoch 3/7\n",
      "27151/27151 [==============================] - 3080s - loss: 0.2997 - acc: 0.8707 - val_loss: 0.2366 - val_acc: 0.8940\n",
      "Epoch 4/7\n",
      "27151/27151 [==============================] - 2822s - loss: 0.2807 - acc: 0.8793 - val_loss: 0.2384 - val_acc: 0.8947\n",
      "Epoch 5/7\n",
      "27151/27151 [==============================] - 2676s - loss: 0.2676 - acc: 0.8839 - val_loss: 0.2497 - val_acc: 0.8946\n",
      "Epoch 6/7\n",
      "27151/27151 [==============================] - 2556s - loss: 0.2607 - acc: 0.8870 - val_loss: 0.2482 - val_acc: 0.8976\n",
      "Epoch 7/7\n",
      "27151/27151 [==============================] - 1749s - loss: 0.2513 - acc: 0.8915 - val_loss: 0.2403 - val_acc: 0.8990\n",
      "4200/4200 [==============================] - 48s    \n",
      "('Test score:', 0.22807268603217035)\n",
      "('Test accuracy:', 0.91023809285390944)\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(train, y_helpful_train, batch_size=50, nb_epoch=7,validation_data=(val, y_helpful_val))\n",
    "score, acc = model.evaluate(test, y_helpful_test,\n",
    "                            batch_size=50)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab)+1, 300, dropout=0.2, mask_zero=True))\n",
    "model.add(LSTM(300, dropout_W=0.2, dropout_U=0.2))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 27151 samples, validate on 6849 samples\n",
      "Epoch 1/7\n",
      "27151/27151 [==============================] - 1151s - loss: 0.5067 - acc: 0.7764 - val_loss: 0.4364 - val_acc: 0.8035\n",
      "Epoch 2/7\n",
      "27151/27151 [==============================] - 1147s - loss: 0.4321 - acc: 0.7939 - val_loss: 0.3794 - val_acc: 0.8204\n",
      "Epoch 3/7\n",
      "27151/27151 [==============================] - 1148s - loss: 0.3961 - acc: 0.8114 - val_loss: 0.3272 - val_acc: 0.8416\n",
      "Epoch 4/7\n",
      "27151/27151 [==============================] - 1147s - loss: 0.3707 - acc: 0.8213 - val_loss: 0.3446 - val_acc: 0.8362\n",
      "Epoch 5/7\n",
      "27151/27151 [==============================] - 1139s - loss: 0.3617 - acc: 0.8283 - val_loss: 0.3334 - val_acc: 0.8464\n",
      "Epoch 6/7\n",
      "27151/27151 [==============================] - 1143s - loss: 0.3505 - acc: 0.8351 - val_loss: 0.3118 - val_acc: 0.8454\n",
      "Epoch 7/7\n",
      "27151/27151 [==============================] - 1155s - loss: 0.3432 - acc: 0.8374 - val_loss: 0.3238 - val_acc: 0.8318\n",
      "4200/4200 [==============================] - 49s    \n",
      "('Test score:', 0.33039839352880207)\n",
      "('Test accuracy:', 0.83452380342142918)\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(train, y_staff_train, batch_size=50, nb_epoch=7,validation_data=(val, y_staff_val))\n",
    "score, acc = model.evaluate(test, y_staff_test,\n",
    "                            batch_size=50)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab)+1, 300, dropout=0.2, mask_zero=True))\n",
    "model.add(LSTM(300, dropout_W=0.2, dropout_U=0.2))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 27151 samples, validate on 6849 samples\n",
      "Epoch 1/7\n",
      "27151/27151 [==============================] - 1161s - loss: 0.4752 - acc: 0.7770 - val_loss: 0.3358 - val_acc: 0.8425\n",
      "Epoch 2/7\n",
      "27151/27151 [==============================] - 1165s - loss: 0.3545 - acc: 0.8345 - val_loss: 0.2863 - val_acc: 0.8623\n",
      "Epoch 3/7\n",
      "27151/27151 [==============================] - 1154s - loss: 0.3258 - acc: 0.8483 - val_loss: 0.2996 - val_acc: 0.8660\n",
      "Epoch 4/7\n",
      "27151/27151 [==============================] - 1152s - loss: 0.3123 - acc: 0.8562 - val_loss: 0.3010 - val_acc: 0.8693\n",
      "Epoch 5/7\n",
      "27151/27151 [==============================] - 1157s - loss: 0.3000 - acc: 0.8632 - val_loss: 0.3244 - val_acc: 0.8616\n",
      "Epoch 6/7\n",
      "27151/27151 [==============================] - 1144s - loss: 0.2962 - acc: 0.8643 - val_loss: 0.3013 - val_acc: 0.8597\n",
      "Epoch 7/7\n",
      "27151/27151 [==============================] - 1678s - loss: 0.2910 - acc: 0.8649 - val_loss: 0.2659 - val_acc: 0.8734\n",
      "4200/4200 [==============================] - 84s    \n",
      "('Test score:', 0.26999765137831372)\n",
      "('Test accuracy:', 0.87380951926821759)\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(train, y_knowledge_train, batch_size=50, nb_epoch=7,validation_data=(val, y_knowledge_val))\n",
    "score, acc = model.evaluate(test, y_knowledge_test,\n",
    "                            batch_size=50)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
