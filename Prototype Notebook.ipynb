{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/abaghel/projects/rnn-patient-sentiment-paper\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prototype the Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape, Merge\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adadelta\n",
    "from keras.constraints import unitnorm, maxnorm\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# This import to resolve some errors with tf version on office server\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data preparation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idx_from_sent(sent, word_idx_map, max_l=51, kernel_size=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x.append(word_idx_map[word])\n",
    "    while len(x) < max_l:\n",
    "        x.append(0)\n",
    "    return x\n",
    "\n",
    "def make_idx_data(revs, word_idx_map, max_l=51, kernel_size=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train, val, test = [], [], []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent(rev['text'], word_idx_map, max_l, kernel_size)\n",
    "        sent.append(rev['y'])\n",
    "        if rev['split'] == 1:\n",
    "            train.append(sent)\n",
    "        elif rev['split'] == 0:\n",
    "            val.append(sent)\n",
    "        else:\n",
    "            test.append(sent)\n",
    "    train = np.array(train, dtype=np.int)\n",
    "    val = np.array(val, dtype=np.int)\n",
    "    test = np.array(test, dtype=np.int)\n",
    "    return [train, val, test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "data loaded!\n"
     ]
    }
   ],
   "source": [
    "print \"loading data...\"\n",
    "x = cPickle.load(open(\"bigger_health-train-val-test2.pickle\", \"rb\"))\n",
    "revs, W, word_idx_map, vocab = x[0], x[1], x[2], x[3]\n",
    "print \"data loaded!\"\n",
    "\n",
    "\n",
    "datasets = make_idx_data(revs, word_idx_map, max_l=247, kernel_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train data preparatio\n",
    "N = datasets[0].shape[0]\n",
    "conv_input_width = W.shape[1]\n",
    "conv_input_height = int(datasets[0].shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:  27155\n",
      "conv_input_height:  247\n",
      "conv_input_width:  300\n"
     ]
    }
   ],
   "source": [
    "print \"N: \", N\n",
    "print \"conv_input_height: \", conv_input_height\n",
    "print \"conv_input_width: \", conv_input_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Prepapration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape = (27155, 247)\n",
      "train_Y.shape = (27155, 2)\n"
     ]
    }
   ],
   "source": [
    "# For each word write a word index (not vector) to X tensor\n",
    "train_X = np.zeros((N, conv_input_height), dtype=np.int)\n",
    "train_Y = np.zeros((N, 2), dtype=np.int)\n",
    "for i in xrange(N):\n",
    "    for j in xrange(conv_input_height):\n",
    "        train_X[i, j] = datasets[0][i, j]\n",
    "    train_Y[i, datasets[0][i, -1]] = 1\n",
    "    \n",
    "    \n",
    "print 'train_X.shape = {}'.format(train_X.shape)\n",
    "print 'train_Y.shape = {}'.format(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30359 18897 32378  8607 30057 24613 35151 17688 13397   437 28698  7844\n",
      " 23124  9241 32378 13814 28736 10380 30196     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0] <type 'numpy.ndarray'> <type 'numpy.ndarray'>\n",
      "[0 1] <type 'numpy.ndarray'> <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print train_X[0] , type(train_X) , type(train_X[0])\n",
    "print train_Y[0] , type(train_Y) , type(train_Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_Y) == train_Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31.1765789,  68.8234211])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.sum(train_Y, axis=0)/float(np.sum(train_Y)))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_X.shape = (6845, 247)\n",
      "val_Y.shape = (6845, 2)\n"
     ]
    }
   ],
   "source": [
    "Nv = datasets[1].shape[0]\n",
    "\n",
    "val_X = np.zeros((Nv, conv_input_height), dtype=np.int)\n",
    "val_Y = np.zeros((Nv, 2), dtype=np.int)\n",
    "for i in xrange(Nv):\n",
    "    for j in xrange(conv_input_height):\n",
    "        val_X[i, j] = datasets[1][i, j]\n",
    "    val_Y[i, datasets[1][i, -1]] = 1\n",
    "    \n",
    "print 'val_X.shape = {}'.format(val_X.shape)\n",
    "print 'val_Y.shape = {}'.format(val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13287   431 11571   112 16982  1204  1074 28736 15865 30613  6482 13814\n",
      " 11571 24777 13194 20697 30352 31539 19006 31539 29072 13033 10002 23027\n",
      " 31539 31983  2943 22730 16643 20903 16859 12153 27346 20722 31539 27346\n",
      " 31983  2943  6892 28022 13683 22146 13287   431 17956 24441 23777  8607\n",
      " 12326 28736 27346 18238 13814 19103 19016  9375 11034 18508 35234 13287\n",
      "  9995 28374 20939  9375 30359 13479 17789 15865 27346 10898 19103  5248\n",
      " 31540 12153 13814 11571  9713  8429 30359  1226 29976 27346 18897 11520\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0] <type 'numpy.ndarray'> <type 'numpy.ndarray'>\n",
      "[1 0] <type 'numpy.ndarray'> <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print val_X[0] , type(val_X) , type(val_X[0])\n",
    "print val_Y[0] , type(val_Y) , type(val_Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(val_Y) == val_Y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim= 35972\n",
      "output_dim= 300\n",
      "weights= [array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  7.41578788e-02,  -1.86807379e-01,   1.21926129e-01, ...,\n",
      "         -1.32260442e-01,   3.41992006e-02,   2.10501035e-04],\n",
      "       [  1.43194227e-02,   6.02296554e-02,   2.19316810e-01, ...,\n",
      "          8.92717242e-02,   4.24648672e-02,   2.71095056e-02],\n",
      "       ..., \n",
      "       [ -2.34375000e-01,   2.14843750e-01,  -1.62109375e-01, ...,\n",
      "          1.59179688e-01,   3.54003906e-02,  -1.13281250e-01],\n",
      "       [ -1.21112600e-01,  -1.87677279e-01,  -2.32269242e-01, ...,\n",
      "         -1.98359162e-01,  -1.15148671e-01,  -8.49112794e-02],\n",
      "       [ -4.46777344e-02,   6.73828125e-02,  -1.41601562e-01, ...,\n",
      "         -1.65039062e-01,   8.98437500e-02,  -5.51757812e-02]], dtype=float32)]\n",
      "W_constraint= <keras.constraints.UnitNorm object at 0x5e3cd90>\n"
     ]
    }
   ],
   "source": [
    "# These will be used in the Embedding layers as paramteres\n",
    "print \"input_dim=\", W.shape[0]\n",
    "print \"output_dim=\", W.shape[1]\n",
    "print \"weights=\", [W]\n",
    "print \"W_constraint=\", unitnorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=W.shape[0], output_dim=W.shape[1], weights=[W], W_constraint=unitnorm()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, 300)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(LSTM(250))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 250)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimizer is adadelta and loss function is categorical_crossentropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27155 samples, validate on 6845 samples\n",
      "Epoch 1/10\n",
      " 2350/27155 [=>............................] - ETA: 640s - loss: 0.6337 - acc: 0.6774"
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, batch_size=50, nb_epoch=10, validation_data=(val_X, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
